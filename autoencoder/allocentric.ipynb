{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9788dd5e",
   "metadata": {},
   "source": [
    "#### Imports and environment creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b96a09a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minigrid.core.constants import COLOR_NAMES\n",
    "from minigrid.core.grid import Grid\n",
    "from minigrid.core.mission import MissionSpace\n",
    "from minigrid.core.world_object import Door, Goal, Key, Wall\n",
    "from minigrid.manual_control import ManualControl\n",
    "from minigrid.minigrid_env import MiniGridEnv\n",
    "from minigrid.core.constants import IDX_TO_OBJECT, OBJECT_TO_IDX\n",
    "import gymnasium as gym\n",
    "\n",
    "from minigrid.core.actions import Actions\n",
    "from dataclasses import dataclass, field \n",
    "from typing import Set\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c267bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2  2  2  2  2  2  2]\n",
      " [ 2 10  1  1  1  1  1  2]\n",
      " [ 2  1  1  1  1  1  1  2]\n",
      " [ 2  1  1  1  1  1  1  2]\n",
      " [ 2  1  1  1  1  1  1  2]\n",
      " [ 2  1  1  1  1  1  1  2]\n",
      " [ 2  1  1  1  1  1  8  2]\n",
      " [ 2  2  2  2  2  2  2  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/tiago/Desktop/Code/SURFiN/mg10/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pos to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pos` for environment variables or `env.get_wrapper_attr('agent_pos')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#Choose grid width/height (the grid is a square)\n",
    "WORLD_N=8\n",
    "WORLD_N_SQ = WORLD_N**2\n",
    "\n",
    "#Choose the gym environment \n",
    "env = gym.make(f\"MiniGrid-Empty-{WORLD_N}x{WORLD_N}-v0\", render_mode=\"rgb_array\")\n",
    "#env = gym.make(f\"MiniGrid-Dynamic-Obstacles-{WORLD_N}x{WORLD_N}-v0\", render_mode=\"rgb_array\")\n",
    "\n",
    "env.valid_actions = {Actions.left, Actions.right, Actions.forward}\n",
    "\n",
    "def get_array_repr(env):\n",
    "    grid_array = env.unwrapped.grid.encode()[:,:,0]\n",
    "    grid_array[env.agent_pos[0],env.agent_pos[1]]=OBJECT_TO_IDX['agent']\n",
    "    return grid_array.T\n",
    "\n",
    "env.reset()\n",
    "print(get_array_repr(env))\n",
    "\n",
    "map_numbers = range(1,11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b14348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gymnasium.wrappers.order_enforcing.OrderEnforcing'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb79be79f30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Render the map\n",
    "print(type(env))\n",
    "env_core = env.unwrapped\n",
    "plt.axis('off')\n",
    "plt.imshow(env_core.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c468843",
   "metadata": {},
   "source": [
    "#### Agent motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83bc3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/tiago/Desktop/Code/SURFiN/mg10/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_dir to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_dir` for environment variables or `env.get_wrapper_attr('agent_dir')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 2,  2,  2,  2,  2,  2,  2,  2,  2, 10,  1,  1,  1,  1,  1,  2,  2,\n",
      "        1,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,\n",
      "        1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1,\n",
      "        1,  1,  1,  8,  2,  2,  2,  2,  2,  2,  2,  2,  2,  4]), array([ 2,  2,  2,  2,  2,  2,  2,  2,  2, 10,  1,  1,  1,  1,  1,  2,  2,\n",
      "        1,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,\n",
      "        1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1,\n",
      "        1,  1,  1,  8,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1]), array([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,\n",
      "       10,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,\n",
      "        1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1,\n",
      "        1,  1,  1,  8,  2,  2,  2,  2,  2,  2,  2,  2,  2,  4])]\n"
     ]
    }
   ],
   "source": [
    "from agents.random import RandomAgent\n",
    "n_steps_train = 8000\n",
    "n_steps_test = 2000\n",
    "\n",
    "random_action_agent = RandomAgent(valid_actions=env.valid_actions)\n",
    "\n",
    "dirarr = ['Right', 'Down', 'Left','Up']\n",
    "actions_to_idx = {Actions.left:0, Actions.right:1, Actions.forward:2}\n",
    "\n",
    "image_list_train = []\n",
    "\n",
    "for i in range(n_steps_train):\n",
    "    action = random_action_agent.act()\n",
    "    arr = get_array_repr(env).flatten()\n",
    "    if (actions_to_idx[action] == 2):\n",
    "        arr = np.append(arr, env.agent_dir)\n",
    "    else:\n",
    "        arr = np.append(arr, 4)    \n",
    "    image_list_train.append(arr)\n",
    "    env.step(action)\n",
    "\n",
    "env.reset()\n",
    "image_list_test = []\n",
    "\n",
    "for i in range(n_steps_test):\n",
    "    action = random_action_agent.act()\n",
    "    arr = get_array_repr(env).flatten()\n",
    "    if (actions_to_idx[action] == 2):\n",
    "        arr = np.append(arr, env.agent_dir)\n",
    "    else:\n",
    "        arr = np.append(arr, 4)    \n",
    "    image_list_test.append(arr)\n",
    "    env.step(action)\n",
    "\n",
    "print(image_list_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4188951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 2,  2,  2,  2,  2,  2,  2,  2,  2, 10,  1,  1,  1,  1,  1,  2,  2,\n",
      "        1,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,\n",
      "        1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1,\n",
      "        1,  1,  1,  8,  2,  2,  2,  2,  2,  2,  2,  2,  2,  4]), array([ 2,  2,  2,  2,  2,  2,  2,  2,  2, 10,  1,  1,  1,  1,  1,  2,  2,\n",
      "        1,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,\n",
      "        1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1,\n",
      "        1,  1,  1,  8,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1]), array([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,\n",
      "       10,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,\n",
      "        1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1,\n",
      "        1,  1,  1,  8,  2,  2,  2,  2,  2,  2,  2,  2,  2,  4])]\n",
      "[array([ 2,  2,  2,  2,  2,  2,  2,  2,  2, 10,  1,  1,  1,  1,  1,  2,  2,\n",
      "        1,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,\n",
      "        1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1,\n",
      "        1,  1,  1,  8,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0]), array([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  1, 10,  1,  1,  1,  1,  2,  2,\n",
      "        1,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,\n",
      "        1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1,\n",
      "        1,  1,  1,  8,  2,  2,  2,  2,  2,  2,  2,  2,  2,  4]), array([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  1, 10,  1,  1,  1,  1,  2,  2,\n",
      "        1,  1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,\n",
      "        1,  1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1,\n",
      "        1,  1,  1,  8,  2,  2,  2,  2,  2,  2,  2,  2,  2,  4])]\n"
     ]
    }
   ],
   "source": [
    "print(image_list_train[:3])\n",
    "print(image_list_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f2565",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db192e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu121\n",
      "True\n",
      "0\n",
      "NVIDIA GeForce MX330\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # This should return True if CUDA is available\n",
    "print(torch.cuda.current_device())  # Shows the current GPU device id (e.g., 0)\n",
    "print(torch.cuda.get_device_name(0))  # Displays the GPU name\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdd3d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Modified) Neuromatch helper funcitons\n",
    "def init_weights_kaiming_normal(layer):\n",
    "  \"\"\"\n",
    "  Initializes weights from linear PyTorch layer\n",
    "  with kaiming normal distribution.\n",
    "\n",
    "  Args:\n",
    "    layer (torch.Module)\n",
    "        Pytorch layer\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  # check for linear PyTorch layer\n",
    "  if isinstance(layer, nn.Linear):\n",
    "    # initialize weights with kaiming normal distribution\n",
    "    nn.init.kaiming_normal_(layer.weight.data)\n",
    "    \n",
    "\n",
    "def runSGD(net, input_train, target_train, input_test, target_test, criterion='mse',\n",
    "           n_epochs=10, batch_size=32, verbose=False):\n",
    "  \"\"\"\n",
    "  Trains autoencoder network with stochastic gradient descent with Adam\n",
    "  optimizer and loss criterion. Train samples are shuffled, and loss is\n",
    "  displayed at the end of each opoch for both MSE and BCE. Plots training loss\n",
    "  at each minibatch (maximum of 500 randomly selected values).\n",
    "\n",
    "  Args:\n",
    "    net (torch network)\n",
    "        ANN object (nn.Module)\n",
    "\n",
    "    input_train (torch.Tensor)\n",
    "        vectorized input images from train set\n",
    "\n",
    "    input_test (torch.Tensor)\n",
    "        vectorized input images from test set\n",
    "\n",
    "    criterion (string)\n",
    "        train loss: 'bce' or 'mse'\n",
    "\n",
    "    n_epochs (boolean)\n",
    "        number of full iterations of training data\n",
    "\n",
    "    batch_size (integer)\n",
    "        number of element in mini-batches\n",
    "\n",
    "    verbose (boolean)\n",
    "        print final loss\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "\n",
    "  # 1. Define the device\n",
    "  # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  device = torch.device('cuda')\n",
    "  print(f\"Using device: {device}\")\n",
    "\n",
    "  # 2. Move the network to the device\n",
    "  net.to(device)\n",
    "\n",
    "  # 3. Move the main tensors to the device (crucial for initial setup)\n",
    "  input_train = input_train.to(device)\n",
    "  target_train = target_train.to(device)\n",
    "  input_test = input_test.to(device)\n",
    "  target_test = target_test.to(device)\n",
    "\n",
    "  # Initialize loss function\n",
    "  if criterion == 'mse':\n",
    "    loss_fn = nn.MSELoss()\n",
    "  elif criterion == 'bce':\n",
    "    loss_fn = nn.BCELoss()\n",
    "  elif criterion == 'cel':\n",
    "    loss_fn = nn.CrossEntropyLoss() \n",
    "  else:\n",
    "    print('Please specify either \"mse\" or \"bce\" for loss criterion')\n",
    "\n",
    "  # Move the loss function to the device if it has parameters (CrossEntropyLoss does not, \n",
    "  # but it's good practice for others like L1Loss which might have reduction='none')\n",
    "  loss_fn.to(device)\n",
    "\n",
    "  # Initialize SGD optimizer\n",
    "  optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "  # Placeholder for loss\n",
    "  track_loss = []\n",
    "\n",
    "  print('Epoch', '\\t', 'Loss train', '\\t', 'Loss test')\n",
    "  for i in range(n_epochs):\n",
    "\n",
    "    \n",
    "    shuffle_idx = np.random.permutation(len(input_train))\n",
    "\n",
    "    batches_input = torch.split(input_train[shuffle_idx], batch_size)\n",
    "    batches_target = torch.split(target_train[shuffle_idx], batch_size)\n",
    "\n",
    "    batches = zip(batches_input, batches_target)\n",
    "\n",
    "\n",
    "    shuffle_idx = np.random.permutation(len(input_train))\n",
    "   \n",
    "    for batch_input, batch_target in batches:\n",
    "      batch_input = batch_input.float()\n",
    "      batch_target = batch_target.float()\n",
    "      output_train = net(batch_input)  # Forward pass on the input batch\n",
    "      loss = loss_fn(output_train, batch_target)  # Compare output with the target\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Keep track of loss at each epoch\n",
    "      track_loss += [float(loss)]\n",
    "\n",
    "    loss_epoch = f'{i+1}/{n_epochs}'\n",
    "    with torch.no_grad():\n",
    "      output_train = net(input_train)\n",
    "      loss_train = loss_fn(output_train, target_train)\n",
    "      loss_epoch += f'\\t {loss_train:.4f}'\n",
    "\n",
    "      output_test = net(input_test)\n",
    "      loss_test = loss_fn(output_test, target_test)\n",
    "      loss_epoch += f'\\t\\t {loss_test:.4f}'\n",
    "\n",
    "    print(loss_epoch)\n",
    "\n",
    "  if verbose:\n",
    "    # Print loss\n",
    "    loss_mse = f'\\nMSE\\t {eval_mse(output_train, target_train):0.4f}'\n",
    "    loss_mse += f'\\t\\t {eval_mse(output_test, target_test):0.4f}'\n",
    "    print(loss_mse)\n",
    "\n",
    "    loss_bce = f'BCE\\t {eval_bce(output_train, target_train):0.4f}'\n",
    "    loss_bce += f'\\t\\t {eval_bce(output_test, target_test):0.4f}'\n",
    "    print(loss_bce)\n",
    "\n",
    "  # Plot loss\n",
    "  step = int(np.ceil(len(track_loss) / 500))\n",
    "  x_range = np.arange(0, len(track_loss), step)\n",
    "  plt.figure()\n",
    "  plt.plot(x_range, track_loss[::step], 'C0')\n",
    "  plt.xlabel('Iterations')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlim([0, None])\n",
    "  plt.ylim([0, None])\n",
    "  plt.show()\n",
    "  return track_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c0d9a3",
   "metadata": {},
   "source": [
    "#### Input preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1276ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2846/1943850101.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  target_train = torch.tensor(target_train, dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1111, 0.1111, 0.1111,  ..., 0.1111, 0.1111, 0.1111],\n",
      "        [0.1111, 0.1111, 0.1111,  ..., 0.1111, 0.1111, 0.1111],\n",
      "        [0.1111, 0.1111, 0.1111,  ..., 0.1111, 0.1111, 0.1111],\n",
      "        ...,\n",
      "        [0.1111, 0.1111, 0.1111,  ..., 0.1111, 0.1111, 0.1111],\n",
      "        [0.1111, 0.1111, 0.1111,  ..., 0.1111, 0.1111, 0.1111],\n",
      "        [0.1111, 0.1111, 0.1111,  ..., 0.1111, 0.1111, 0.1111]])\n",
      "tensor([[0.1111, 0.1111, 0.1111,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        [0.1111, 0.1111, 0.1111,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1111, 0.1111, 0.1111,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.1111, 0.1111, 0.1111,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        [0.1111, 0.1111, 0.1111,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        [0.1111, 0.1111, 0.1111,  ..., 0.0000, 0.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# test_size=0.2\n",
    "# cutoff = int((1-test_size)*len(image_list))\n",
    "X_train, X_test = image_list_train, image_list_test \n",
    "\n",
    "target_train = X_train[1:]\n",
    "input_train = X_train[:-1]\n",
    "target_test = X_test[1:]\n",
    "input_test = X_test[:-1]\n",
    "\n",
    "target_train = torch.tensor(target_train, dtype=torch.int64)\n",
    "input_train = torch.tensor(input_train, dtype=torch.int64)\n",
    "target_test = torch.tensor(target_test, dtype=torch.int64)\n",
    "input_test = torch.tensor(input_test, dtype=torch.int64)\n",
    "\n",
    "def normalise(a,classes):\n",
    "    \n",
    "    output = []\n",
    "    maxi = max(classes)\n",
    "    mini = min(classes)\n",
    "    for i in a:\n",
    "        output.append((i-mini)/(maxi-mini))\n",
    "    \n",
    "    return output\n",
    "\n",
    "#One-hot encoding of discrete integer variable in range [0, num_classes)\n",
    "def one_hot_encode(values, num_classes):\n",
    "    one_hot = torch.zeros(num_classes)\n",
    "    one_hot[values] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Function to process the entire array (each input array of shape [length])\n",
    "def process_input(input_array, mode):\n",
    "    if mode == 'in':\n",
    "    \n",
    "        world_map = torch.tensor(normalise(input_array[:-1], map_numbers))\n",
    "        \n",
    "        action_encoding = one_hot_encode(input_array[WORLD_N_SQ], 5)\n",
    "        \n",
    "        return torch.cat([world_map, action_encoding], dim=0)\n",
    "    elif mode == 'out':\n",
    "        return torch.tensor(normalise(input_array[:-1], map_numbers))\n",
    "\n",
    "# Apply to the whole dataset\n",
    "input_train_processed = torch.stack([process_input(x, 'in') for x in input_train])\n",
    "input_test_processed = torch.stack([process_input(x, 'in') for x in input_test])\n",
    "target_train_processed = torch.stack([process_input(x, 'out') for x in target_train])\n",
    "target_test_processed = torch.stack([process_input(x, 'out') for x in target_test])\n",
    "\n",
    "print(target_train_processed)\n",
    "print(input_train_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b84df5",
   "metadata": {},
   "source": [
    "#### Autoencoder definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de53dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Module\n",
    "\n",
    "class RNNOutOnly(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(*args, **kwargs)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43198093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder \n",
      "\n",
      " Sequential(\n",
      "  (0): Linear(in_features=69, out_features=1035, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=1035, out_features=50, bias=True)\n",
      "  (3): ReLU()\n",
      ")\n",
      "\n",
      "Latent \n",
      "\n",
      " Sequential(\n",
      "  (4): RNNOutOnly(\n",
      "    (rnn): RNN(50, 50)\n",
      "  )\n",
      ")\n",
      "\n",
      "Decoder \n",
      "\n",
      " Sequential(\n",
      "  (5): Linear(in_features=50, out_features=960, bias=True)\n",
      "  (6): ReLU()\n",
      "  (7): Linear(in_features=960, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoding_size=50\n",
    "hidden_fac=15\n",
    "input_size=input_train_processed.size(1)\n",
    "output_size = target_train_processed.size(1)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, int(input_size * hidden_fac)),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(int(input_size * hidden_fac), encoding_size),\n",
    "    nn.ReLU(),\n",
    "    RNNOutOnly(encoding_size, encoding_size,nonlinearity='relu'),\n",
    "    nn.Linear(encoding_size, int(output_size * hidden_fac)),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(int(output_size *hidden_fac), output_size),\n",
    "    )\n",
    "\n",
    "# model[:-2].apply(init_weights_kaiming_normal)\n",
    "\n",
    "n_e = 4\n",
    "n_d = 3\n",
    "encoder = model[:n_e]\n",
    "latent = model[n_e:-n_d]\n",
    "decoder = model[-n_d:]\n",
    "print(f'Encoder \\n\\n {encoder}\\n')\n",
    "print(f'Latent \\n\\n {latent}\\n')\n",
    "print(f'Decoder \\n\\n {decoder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c672a46",
   "metadata": {},
   "source": [
    "#### Autoencoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19c23a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch \t Loss train \t Loss test\n",
      "1/20\t 0.0138\t\t 0.0140\n",
      "2/20\t 0.0095\t\t 0.0102\n",
      "3/20\t 0.0059\t\t 0.0066\n",
      "4/20\t 0.0034\t\t 0.0040\n",
      "5/20\t 0.0017\t\t 0.0021\n",
      "6/20\t 0.0007\t\t 0.0009\n",
      "7/20\t 0.0003\t\t 0.0004\n",
      "8/20\t 0.0002\t\t 0.0002\n",
      "9/20\t 0.0001\t\t 0.0001\n",
      "10/20\t 0.0001\t\t 0.0001\n",
      "11/20\t 0.0000\t\t 0.0001\n",
      "12/20\t 0.0000\t\t 0.0000\n",
      "13/20\t 0.0000\t\t 0.0000\n",
      "14/20\t 0.0000\t\t 0.0000\n",
      "15/20\t 0.0000\t\t 0.0000\n",
      "16/20\t 0.0000\t\t 0.0000\n",
      "17/20\t 0.0000\t\t 0.0000\n",
      "18/20\t 0.0000\t\t 0.0000\n",
      "19/20\t 0.0000\t\t 0.0000\n",
      "20/20\t 0.0000\t\t 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 256\n",
    "\n",
    "tracked_losses = runSGD(model, input_train_processed, target_train_processed, input_test_processed, target_test_processed, n_epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c0c54bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03131341189146042, 0.02548695169389248, 0.022034548223018646, 0.01974056102335453, 0.01854782924056053, 0.017837155610322952, 0.016658343374729156, 0.015638679265975952, 0.014877630397677422, 0.014624116942286491, 0.015222861431539059, 0.014757773838937283, 0.015060918405652046, 0.014599956572055817, 0.01453319564461708, 0.014407827518880367, 0.014124194160103798, 0.014095867983996868, 0.013803021050989628, 0.013591654598712921, 0.013882734812796116, 0.013658741489052773, 0.013568233698606491, 0.013469232246279716, 0.01289062574505806, 0.012879153713583946, 0.012532925233244896, 0.012395554222166538, 0.012435254640877247, 0.012252986431121826, 0.011868538334965706, 0.011615089140832424, 0.011464769020676613, 0.011149019002914429, 0.010679887607693672, 0.010560911148786545, 0.010384926572442055, 0.010234883055090904, 0.010583892464637756, 0.009865418076515198, 0.009869523346424103, 0.009141385555267334, 0.008967367932200432, 0.008946471847593784, 0.009046055376529694, 0.008211460895836353, 0.008207118138670921, 0.008015247993171215, 0.008066254667937756, 0.007479950785636902, 0.007505611050873995, 0.0069406237453222275, 0.007391126826405525, 0.007428969722241163, 0.007148517295718193, 0.00626780092716217, 0.007129029370844364, 0.006446055136620998, 0.00619009044021368, 0.0059980470687150955, 0.006347427144646645, 0.00506970938295126, 0.00521085923537612, 0.005686531309038401, 0.005135845392942429, 0.005736206658184528, 0.0052026244811713696, 0.0054976013489067554, 0.005629679653793573, 0.005378939677029848, 0.004454303532838821, 0.004857414402067661, 0.004676148761063814, 0.004160383716225624, 0.00509213749319315, 0.004462864249944687, 0.004056286998093128, 0.0040029482915997505, 0.004625419154763222, 0.003389024641364813, 0.004250046797096729, 0.003910732455551624, 0.003985234536230564, 0.004088294226676226, 0.0036657596938312054, 0.003909484948962927, 0.0037154892925173044, 0.003559761680662632, 0.0033551747910678387, 0.0030419223476201296, 0.0028429501689970493, 0.003486956935375929, 0.003368212142959237, 0.003069269238039851, 0.0028363927267491817, 0.002553849248215556, 0.0022846837528049946, 0.0030923387967050076, 0.0027743112295866013, 0.002739840652793646, 0.0025226694997400045, 0.0026577480603009462, 0.002651304705068469, 0.002049472415819764, 0.0021034684032201767, 0.0020596918184310198, 0.002384003484621644, 0.002610004972666502, 0.0016386553179472685, 0.0020712458062916994, 0.0019283529836684465, 0.0022075914312154055, 0.0016342753078788519, 0.0020059337839484215, 0.001846398925408721, 0.0019323445158079267, 0.001779056154191494, 0.0017715601716190577, 0.0016324151074513793, 0.001580715412274003, 0.0017542267451062799, 0.001465175999328494, 0.0017472825711593032, 0.0014149544294923544, 0.0014959678519517183, 0.0014601878356188536, 0.0014857267960906029, 0.0017813631566241384, 0.0015038903802633286, 0.0014970439951866865, 0.0010839735623449087, 0.0012184844817966223, 0.001338489819318056, 0.0011681151809170842, 0.0011332007125020027, 0.00115464988630265, 0.0010508664418011904, 0.0010665298905223608, 0.0008497329545207322, 0.0008716891752555966, 0.0010677552781999111, 0.001051089959219098, 0.0008200327283702791, 0.0008836218621581793, 0.0009375240188091993, 0.0007812874391674995, 0.0008176927221938968, 0.0007975781336426735, 0.0007542562671005726, 0.0006332569755613804, 0.0008775988826528192, 0.0005651669343933463, 0.000702657678630203, 0.0006032845703884959, 0.0007522764499299228, 0.0008918300154618919, 0.0007798530859872699, 0.0007205608999356627, 0.0006143457139842212, 0.0007265046006068587, 0.0006351342308335006, 0.00058040238218382, 0.0004077626799698919, 0.0006323650013655424, 0.0005688696401193738, 0.00047575507778674364, 0.000526907155290246, 0.00042681198101490736, 0.00040699250530451536, 0.0005321246571838856, 0.0005581394070759416, 0.0005871737375855446, 0.0005417980719357729, 0.0005529316258616745, 0.0004373488773126155, 0.000510944752022624, 0.0003577676834538579, 0.000488139659864828, 0.00023661958402954042, 0.00032010715221986175, 0.0005029731546528637, 0.00036290448042564094, 0.0003203581436537206, 0.0003508716181386262, 0.00036082809674553573, 0.0004395487776491791, 0.00035908754216507077, 0.00031899125315248966, 0.00022853491827845573, 0.00022902159253135324, 0.0002772643347270787, 0.0003499493468552828, 0.00038235902320593596, 0.00026856514159590006, 0.0002678906312212348, 0.0002267843228764832, 0.00031380500877276063, 0.00021491001825779676, 0.00026090876781381667, 0.0002013937191804871, 0.00022202011314220726, 0.00024256351753138006, 0.00019370944937691092, 0.00022903889475855976, 0.00024947564816102386, 0.00017535155348014086, 0.00020728737581521273, 0.00022147937852423638, 0.0001776155550032854, 0.00019483146024867892, 0.0002294049772899598, 0.00018095536506734788, 0.00019959354540333152, 0.00015599829202983528, 0.0001515747862868011, 0.00011508497118484229, 0.00013891005073674023, 0.00021189372637309134, 0.00019749980128835887, 0.00017497762746643275, 0.00019391535897739232, 0.00018807366723194718, 0.00019262588466517627, 0.0001020747295115143, 0.00013140923692844808, 0.00011148181511089206, 0.0001304426696151495, 0.00011276679288130254, 0.00011923265265068039, 0.0001413157588103786, 0.00016851225518621504, 0.0001419645850546658, 0.0001553598267491907, 0.00011037535296054557, 0.0001231274800375104, 0.00015954869741108268, 5.371707084123045e-05, 8.410646842094138e-05, 0.00011111165804322809, 9.600770863471553e-05, 9.26122156670317e-05, 7.579500379506499e-05, 0.0001463603402953595, 9.372126078233123e-05, 9.593163849785924e-05, 8.874158083926886e-05, 6.951380055397749e-05, 0.00012076085840817541, 0.00012102451000828296, 9.490592492511496e-05, 0.00012006099859718233, 9.85687438515015e-05, 5.6193726777564734e-05, 6.47206325083971e-05, 0.0001043614320224151, 7.017255848040804e-05, 0.00011593918316066265, 7.833624113118276e-05, 8.621976303402334e-05, 0.00010128009307663888, 9.28282825043425e-05, 7.681157876504585e-05, 8.066146983765066e-05, 6.035675687598996e-05, 6.0833554016426206e-05, 5.634754052152857e-05, 4.685072781285271e-05, 4.884936424787156e-05, 4.2234722059220076e-05, 6.735587521689013e-05, 3.954783096560277e-05, 9.246863191947341e-05, 4.5767930714646354e-05, 5.585689359577373e-05, 6.572503480128944e-05, 6.742954428773373e-05, 3.805338201345876e-05, 3.925755663658492e-05, 6.538427987834439e-05, 3.870037471642718e-05, 2.905475594161544e-05, 4.634084689314477e-05, 5.4201977036427706e-05, 4.870592965744436e-05, 7.24131241440773e-05, 3.5025757824769244e-05, 2.6620860808179714e-05, 3.338494570925832e-05, 4.8247842642012984e-05, 2.4898861738620326e-05, 2.8067206585546955e-05, 4.5361510274233297e-05, 4.5546246838057414e-05, 4.200452531222254e-05, 4.102809907635674e-05, 5.0756047130562365e-05, 3.6100791476201266e-05, 2.9096609068801627e-05, 5.583099846262485e-05, 2.3189641069620848e-05, 3.068535079364665e-05, 3.426175317144953e-05, 2.310498894075863e-05, 2.2990034267422743e-05, 6.64847539155744e-05, 2.3901560780359432e-05, 1.9941307982662693e-05, 3.749181632883847e-05, 3.1917341402731836e-05, 3.1295345252146944e-05, 3.369249316165224e-05, 4.138653457630426e-05, 2.6246603738400154e-05, 1.9433617126196623e-05, 3.785997978411615e-05, 2.8665321224252693e-05, 1.9090377463726327e-05, 1.9539642380550504e-05, 3.709078373503871e-05, 1.9362911189091392e-05, 1.451715434086509e-05, 2.6266494387527928e-05, 5.060464536654763e-05, 2.918124846473802e-05, 3.142809873679653e-05, 3.3803728001657873e-05, 2.5190181986545213e-05, 1.3868731912225485e-05, 1.922802948683966e-05, 1.717005216050893e-05, 1.6066565876826644e-05, 2.6701991373556666e-05, 2.1080977603560314e-05, 2.0990939447074197e-05, 1.7676888091955334e-05, 2.261727786390111e-05, 3.292577457614243e-05, 1.6041338312788866e-05, 1.8970074961544015e-05, 1.9898048776667565e-05, 1.5287474525393918e-05, 2.2703672584611923e-05, 2.3640608560526744e-05, 1.3256304555397946e-05, 1.4004740478412714e-05, 1.4698112863698043e-05, 1.7481917893746868e-05, 1.3966857295599766e-05, 2.3874428734416142e-05, 1.9647228327812627e-05, 1.3853917153028306e-05, 9.289332410844509e-06, 1.6844578567543067e-05, 2.6246707420796156e-05, 2.3973057977855206e-05, 1.5866624380578287e-05, 1.3630598914460279e-05, 1.1052739864680916e-05, 1.7747897800290957e-05, 1.1482768968562596e-05, 1.0909338016062975e-05, 1.621974297449924e-05, 1.526732557977084e-05, 1.7979107724386267e-05, 1.2679596693487838e-05, 1.5164921023824718e-05, 1.5627421817043796e-05, 8.396431439905427e-06, 1.2078879990440328e-05, 9.83613972493913e-06, 1.374369821860455e-05, 9.434744242753368e-06, 1.0514638233871665e-05, 1.5438250557053834e-05, 9.361558113596402e-06, 1.1194380022061523e-05, 1.1244546840316616e-05, 1.4883504263707437e-05, 7.680824637645856e-06, 8.375680408789776e-06, 9.219931598636322e-06, 1.460450585000217e-05, 9.512004908174276e-06, 6.543355539179174e-06, 6.910237971169408e-06, 7.989309779077303e-06, 1.0798650691867806e-05, 7.4914132710546255e-06, 1.1973563232459128e-05, 9.697676432551816e-06, 7.125029696908314e-06, 8.336231985595077e-06, 8.65435868036002e-06, 1.2005439202766865e-05, 9.462173693464138e-06, 5.086803867015988e-06, 1.0677548743842635e-05, 6.4305609157599974e-06, 8.554334272048436e-06, 1.8516075215302408e-05, 1.0927044968411792e-05, 9.034680260811001e-06, 1.0086736438097432e-05, 6.223705440788763e-06, 9.416407010576222e-06, 6.021831723046489e-06, 1.0272859071847051e-05, 1.3475277228280902e-05, 1.2140499165980145e-05, 6.331019449135056e-06, 6.671861683571478e-06, 1.0307847333024256e-05, 5.7948086578107905e-06, 7.185759841377148e-06, 8.354337296623271e-06, 6.729079359502066e-06, 9.163161848846357e-06, 7.577989435958443e-06, 5.580118340731133e-06, 7.991509846760891e-06, 6.168249001348158e-06, 6.765121725038625e-06, 6.057047357899137e-06, 8.685829016030766e-06, 6.746769031451549e-06, 8.096029887383338e-06, 6.914177902217489e-06, 7.978123903740197e-06, 7.2613720476510935e-06, 3.885611477016937e-06, 5.173998943064362e-06, 7.22241884432151e-06, 6.332563316391315e-06, 8.137731128954329e-06, 4.920041192235658e-06, 7.221409759949893e-06, 7.214026027213549e-06, 4.451202585187275e-06, 4.490190804062877e-06, 4.342096417531138e-06, 4.0014028854784556e-06, 5.692333161277929e-06, 5.124731160321971e-06, 4.332371645432431e-06, 5.6220628721348476e-06, 7.0982750912662596e-06, 4.524324140220415e-06, 7.00247437634971e-06, 6.307178409770131e-06, 5.628901817544829e-06, 3.1825047699385323e-06, 3.831503363471711e-06, 2.750347448454704e-06, 8.675458957441151e-06, 3.1001161460153526e-06, 5.268002951197559e-06, 4.748901574203046e-06, 6.373318683472462e-06, 5.141137535247253e-06, 5.827602763019968e-06, 3.484535227471497e-06, 2.659026904439088e-06, 6.355179721140303e-06, 3.620114057412138e-06, 4.787189482158283e-06, 4.7738649300299585e-06, 3.4159907045250293e-06, 5.839963705511764e-06, 4.219021320750471e-06, 3.2944574286375428e-06, 3.7427100778586464e-06, 3.908514372596983e-06, 3.615427885961253e-06, 2.7056435101258103e-06, 4.034430276078638e-06, 5.260239959170576e-06, 4.418579464982031e-06, 4.975641331839142e-06, 4.355844339443138e-06, 2.485744516889099e-06, 4.981039637641516e-06, 3.463130269665271e-06, 2.6043751404358773e-06, 3.488293032205547e-06, 4.163831363257486e-06, 4.255565272615058e-06, 4.387647550174734e-06, 2.2557564989256207e-06, 2.9077566523483256e-06, 3.6262404137232807e-06, 3.748233666556189e-06, 3.7060801787447417e-06, 2.6885409170063213e-06, 2.354294338147156e-06, 2.2522726794704795e-06, 2.63282186097058e-06, 6.11825362284435e-06, 4.104076197108952e-06, 2.5856757019937504e-06, 4.606828042597044e-06, 2.1407274743978633e-06, 3.137330168101471e-06, 4.0987201828102116e-06, 2.965580051750294e-06, 3.980068868258968e-06, 3.994769031123724e-06, 2.451884483889444e-06, 2.0947641132806893e-06, 2.2163280846143607e-06, 2.6020140921900747e-06, 3.448808001849102e-06, 3.610664634834393e-06, 2.512404080334818e-06, 3.730981916305609e-06, 2.9953462217235938e-06, 2.968686658277875e-06, 3.1141407816903666e-06, 3.2392031243944075e-06, 2.2541148609889206e-06, 2.759973085630918e-06, 2.8205759008415043e-06, 3.7466704725375166e-06, 5.4005731726647355e-06, 7.164088401623303e-06, 1.108616834244458e-05, 1.5836776583455503e-05, 2.0342287825769745e-05, 2.466630030539818e-05, 2.6741923647932708e-05, 2.292157478223089e-05, 1.331073963228846e-05, 6.122998456703499e-06, 6.5610101955826394e-06, 8.010502824618015e-06, 8.966239875007886e-06, 5.313800102157984e-06, 3.883951649186201e-06, 5.602988039754564e-06, 6.724497325194534e-06, 5.5848099691502284e-06, 5.519425940292422e-06, 4.97100791108096e-06, 4.104977506358409e-06, 3.7468171285581775e-06, 5.385951226344332e-06, 4.163319772487739e-06, 4.6403156375163235e-06, 4.350608378445031e-06, 4.0660693230165634e-06, 3.921104053006275e-06, 3.0719606911588926e-06, 2.9973102755320724e-06, 3.0756214073335286e-06, 3.3822821023932192e-06, 3.2425227800558787e-06, 2.5795809506234946e-06, 3.4177996894868556e-06, 2.5373637981829233e-06, 3.193452357663773e-06, 3.4947179301525466e-06, 2.7565881737245945e-06, 2.972267338918755e-06, 2.9420434657367878e-06, 2.287004917889135e-06, 2.1432674657262396e-06, 2.841793047991814e-06, 2.892199518100824e-06, 2.339065304113319e-06, 2.4134758405125467e-06, 2.0018756003992166e-06, 2.27142550102144e-06, 2.020194187934976e-06, 2.358574192840024e-06, 2.3624261302757077e-06, 2.7970168048341293e-06, 1.5726014908068464e-06, 2.532210601202678e-06, 2.7905757633561734e-06, 2.102839971485082e-06, 2.3424013306794222e-06, 1.6262677036138484e-06, 1.74597994373471e-06, 2.434961061226204e-06, 2.86712747765705e-06, 1.5949484577504336e-06, 2.8248277885722928e-06, 1.877914542092185e-06, 2.084181005557184e-06, 2.1742473563790554e-06, 2.825114734150702e-06, 3.644535809144145e-06, 3.8229263736866415e-06, 4.714203441835707e-06, 5.414750830823323e-06, 5.41630879524746e-06, 5.186085218156222e-06, 5.025521204515826e-06, 4.661458660848439e-06, 5.327061899151886e-06, 7.557806384284049e-06, 8.321831046487205e-06, 7.657035894226283e-06, 7.637470844201744e-06, 6.645653229497839e-06, 5.051228072261438e-06, 3.882205419358797e-06, 3.715142838700558e-06, 1.3204139577283058e-06, 1.9023633512915694e-06, 2.388740540482104e-06, 3.582421413739212e-06, 4.338261533121113e-06, 5.991223588353023e-06, 6.578252396138851e-06, 6.583368758583674e-06, 5.6206290537375025e-06, 3.447352128205239e-06, 2.62708908849163e-06, 2.3376383069262374e-06, 2.514977268219809e-06, 2.173664370275219e-06, 2.338344984309515e-06, 1.760498321345949e-06, 2.3159523152571637e-06, 2.4826636035868432e-06, 2.650655460456619e-06, 1.9033902844967088e-06, 1.8362877653999021e-06, 1.5252793446052237e-06, 1.744899805089517e-06, 1.6887340734683676e-06, 1.392102831232478e-06, 1.871578888312797e-06, 2.123772446793737e-06, 1.876535407063784e-06, 1.6589206097705755e-06, 1.823387492549955e-06, 1.4677654007755336e-06, 1.7869856492325198e-06, 1.1941014008698403e-06]\n"
     ]
    }
   ],
   "source": [
    "print(tracked_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de23687",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c6af472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2, 2,  ..., 2, 2, 2],\n",
      "        [2, 2, 2,  ..., 2, 2, 2],\n",
      "        [2, 2, 2,  ..., 2, 2, 2],\n",
      "        ...,\n",
      "        [2, 2, 2,  ..., 2, 2, 2],\n",
      "        [2, 2, 2,  ..., 2, 2, 2],\n",
      "        [2, 2, 2,  ..., 2, 2, 2]])\n",
      "MSE Loss at the end of all the epochs: 1.6231480913120322e-05\n",
      "Cell accuracy: 0.9999921835917959\n",
      "Number of agents accuracy: 0.9994997498749375\n",
      "Agent location accuracy: 1.0\n",
      "Perfectness: 0.9994997498749375\n"
     ]
    }
   ],
   "source": [
    "input_test_processed = input_test_processed.to(device)\n",
    "output = model(input_test_processed)  # Model output (logits or probabilities)\n",
    "output = output.cpu() \n",
    "\n",
    "# Initialize a list to hold the decoded outputs for each observation\n",
    "decoded_outputs = []\n",
    "\n",
    "incorrect_agent_num=0\n",
    "incorrect_agent_location=0\n",
    "incorrect_cell=0\n",
    "not_perfect=0\n",
    "\n",
    "for i in range(output.size(0)):  # Loop over each sample in the batch\n",
    "    # Extract the blocks of the output\n",
    "    decoded_map = output[i]\n",
    "    resized_decoded_map = decoded_map*(max(map_numbers)-min(map_numbers))+min(map_numbers)\n",
    "    rounded_decoded_map = torch.round(resized_decoded_map).long()\n",
    "    \n",
    "    num_agents = 0\n",
    "    maybe_perfect=1\n",
    "\n",
    "    for j, val in enumerate(rounded_decoded_map):\n",
    "        if val== 10:\n",
    "            num_agents +=1\n",
    "            if (target_test[i, j] != 10):\n",
    "                incorrect_agent_location=1\n",
    "        if (target_test[i, j] != val):\n",
    "            # print(\"cell\", i)\n",
    "            maybe_perfect=0\n",
    "            incorrect_cell +=1\n",
    "\n",
    "    if num_agents != 1:\n",
    "        decoded_second = torch.tensor(-1, dtype=torch.long)\n",
    "        maybe_perfect=0\n",
    "        incorrect_agent_num +=1\n",
    "\n",
    "    if not maybe_perfect:\n",
    "        not_perfect +=1\n",
    "\n",
    "    # Use torch.masked_select to get all matching values\n",
    "    matches = torch.masked_select(rounded_decoded_map, rounded_decoded_map == 10)\n",
    "    \n",
    "    # Append the decoded sample to the final list\n",
    "    decoded_outputs.append(rounded_decoded_map)\n",
    "\n",
    "acc_cell = 1.0-(incorrect_cell/(WORLD_N_SQ*output.size(0)))\n",
    "acc_agentloc = 1.0-(incorrect_agent_location/output.size(0))\n",
    "acc_agentnum = 1.0-(incorrect_agent_num/output.size(0))\n",
    "acc_perfect = 1.0-(not_perfect/output.size(0))\n",
    "\n",
    "# Convert to tensor if needed\n",
    "decoded_outputs = torch.stack(decoded_outputs)\n",
    "print(decoded_outputs)\n",
    "\n",
    "print (\"MSE Loss at the end of all the epochs:\", tracked_losses[-1])\n",
    "print (\"Cell accuracy:\", acc_cell)\n",
    "print (\"Number of agents accuracy:\", acc_agentnum)\n",
    "print (\"Agent location accuracy:\", acc_agentloc)\n",
    "print (\"Perfectness:\", acc_perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7485691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1301:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1302:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1303:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 0\n",
      "==================================================\n",
      "Sample 1304:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1305:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "==================================================\n",
      "Sample 1306:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "==================================================\n",
      "Sample 1307:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1308:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1309:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1310:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 0\n",
      "==================================================\n",
      "Sample 1311:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 0\n",
      "==================================================\n",
      "Sample 1312:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1313:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 3\n",
      "==================================================\n",
      "Sample 1314:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1315:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "==================================================\n",
      "Sample 1316:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1317:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "==================================================\n",
      "Sample 1318:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "==================================================\n",
      "Sample 1319:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1320:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1321:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1322:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1323:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 3\n",
      "==================================================\n",
      "Sample 1324:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 3\n",
      "==================================================\n",
      "Sample 1325:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1326:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 0\n",
      "==================================================\n",
      "Sample 1327:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1328:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 3\n",
      "==================================================\n",
      "Sample 1329:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n",
      "Sample 1330:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 4\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "interval_min=1300\n",
    "interval_size=30\n",
    "for i in range(interval_min,interval_min+min(interval_size,decoded_outputs.size(0))):\n",
    "    # Print the input, decoded grid, and target test grid side by side\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    \n",
    "    # Input grid \n",
    "    print(\"Input Grid:\")\n",
    "    print(input_test[i, :WORLD_N_SQ].reshape(WORLD_N, WORLD_N).int())\n",
    "    \n",
    "    # Decoded /output grid \n",
    "    print(\"Decoded Grid:\")\n",
    "    print(decoded_outputs[i, :WORLD_N_SQ].reshape(WORLD_N, WORLD_N).int())\n",
    "    \n",
    "    # Target grid \n",
    "    print(\"Target Grid:\")\n",
    "    print(target_test[i, :WORLD_N_SQ].reshape(WORLD_N, WORLD_N).int())\n",
    "    \n",
    "    # Provided action \n",
    "    print(f\"Input Action: {input_test[i, WORLD_N_SQ].item()}\")\n",
    "    \n",
    "    print(\"=\" * 50)  # Separator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f2204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mg10 (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
